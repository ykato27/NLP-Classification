{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorchを使ってLSTMで文章分類を実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データ準備\n",
    "livedoorニュースコーパスの「ldcc-20140209.tar.gz」データをダウンロードします。\n",
    "https://www.rondhuit.com/download.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データフレーム作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dokujo-tsushin', 'it-life-hack', 'kaden-channel', 'livedoor-homme', 'movie-enter', 'peachy', 'smax', 'sports-watch', 'topic-news']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import linecache\n",
    "\n",
    "# カテゴリを配列で取得\n",
    "categories = [name for name in os.listdir(\"text\") if os.path.isdir(\"text/\" + name)]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ドコモ、薄さ6.7mmの極薄スマホを発売へ！ドコモ、「MEDIAS ES N-05D」が凄い...</td>\n",
       "      <td>it-life-hack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>組み合わせ自由自在！自分だけのヘッドフォンKOTORI101は素敵な相棒【売れ筋チェック】\\n</td>\n",
       "      <td>kaden-channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>【週末映画まとめ読み】宮崎あおい「いろいろな夫婦の形がある」\\n</td>\n",
       "      <td>movie-enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>本格的音ゲーで遊ぼう！リズムギターゲーム「MIWA ROCK!!」【Androidアプリ】\\n</td>\n",
       "      <td>smax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>「自分で言っちゃった」川澄が明かす、遅咲きのサッカー人生\\n</td>\n",
       "      <td>sports-watch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title       category\n",
       "0  ドコモ、薄さ6.7mmの極薄スマホを発売へ！ドコモ、「MEDIAS ES N-05D」が凄い...   it-life-hack\n",
       "1    組み合わせ自由自在！自分だけのヘッドフォンKOTORI101は素敵な相棒【売れ筋チェック】\\n  kaden-channel\n",
       "2                   【週末映画まとめ読み】宮崎あおい「いろいろな夫婦の形がある」\\n    movie-enter\n",
       "3    本格的音ゲーで遊ぼう！リズムギターゲーム「MIWA ROCK!!」【Androidアプリ】\\n           smax\n",
       "4                     「自分で言っちゃった」川澄が明かす、遅咲きのサッカー人生\\n   sports-watch"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = pd.DataFrame(columns=[\"title\", \"category\"])\n",
    "for cat in categories:\n",
    "    path = \"text/\" + cat + \"/*.txt\"\n",
    "    files = glob(path)\n",
    "    for text_name in files:\n",
    "        title = linecache.getline(text_name, 3)\n",
    "        s = pd.Series([title, cat], index=datasets.columns)\n",
    "        datasets = datasets.append(s, ignore_index=True)\n",
    "\n",
    "# データフレームシャッフル\n",
    "datasets = datasets.sample(frac=1).reset_index(drop=True)\n",
    "datasets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### インプットデータの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1269, 1.7695, 0.4270, 0.7358, 1.3951, 0.7040]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "tensor([[ 0.1269,  1.7695,  0.4270,  0.7358,  1.3951,  0.7040],\n",
      "        [ 0.8079, -1.2917,  1.5329, -1.5326,  1.3140, -1.9458],\n",
      "        [ 0.2971, -0.2062,  1.0666, -0.4973,  0.3154,  0.0591]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 以下の宣言で行が単語ベクトル、列が単語のインデックスのマトリクスを生成してる感じ\n",
    "embeds = nn.Embedding(10, 6) # (Embedding(単語の合計数, ベクトル次元数))\n",
    "\n",
    "# ３行目の要素を取り出したいならば\n",
    "w1 = torch.tensor([2])\n",
    "print(embeds(w1))\n",
    "# tensor([[-1.5947, -0.8387,  0.7669, -0.9644, -0.7902,  2.7167]],\n",
    "#        grad_fn=<EmbeddingBackward>)\n",
    "\n",
    "# 3行目、5行目、１０行目の要素を取り出したいならば、\n",
    "w2 = torch.tensor([2,4,9])\n",
    "print(embeds(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['人工', '知能', 'は', '人間', 'の', '仕事', 'を', '奪っ', 'た']\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "import re\n",
    "import torch\n",
    "\n",
    "tagger = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "def make_wakati(sentence):\n",
    "    # MeCabで分かち書き\n",
    "    sentence = tagger.parse(sentence)\n",
    "    # 半角全角英数字除去\n",
    "    sentence = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", sentence)\n",
    "    # 記号もろもろ除去\n",
    "    sentence = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", sentence)\n",
    "    # スペースで区切って形態素の配列へ\n",
    "    wakati = sentence.split(\" \")\n",
    "    # 空の要素は削除\n",
    "    wakati = list(filter((\"\").__ne__, wakati))\n",
    "    return wakati\n",
    "\n",
    "# テスト\n",
    "test = \"【人工知能】は「人間」の仕事を奪った\"\n",
    "print(make_wakati(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size :  13229\n",
      "tensor([5648,    3,  863, 2066,   90, 1379,  235,  463,    3, 5649, 5650, 1128,\n",
      "        6131])\n"
     ]
    }
   ],
   "source": [
    "# 単語ID辞書を作成する\n",
    "word2index = {}\n",
    "for title in datasets[\"title\"]:\n",
    "    wakati = make_wakati(title)\n",
    "    for word in wakati:\n",
    "        if word in word2index: continue\n",
    "        word2index[word] = len(word2index)\n",
    "print(\"vocab size : \", len(word2index))\n",
    "\n",
    "# 文章を単語IDの系列データに変換\n",
    "# PyTorchのLSTMのインプットになるデータなので、もちろんtensor型で\n",
    "def sentence2index(sentence):\n",
    "    wakati = make_wakati(sentence)\n",
    "    return torch.tensor([word2index[w] for w in wakati], dtype=torch.long)\n",
    "\n",
    "# テスト\n",
    "test = \"例のあのメニューも！ニコニコ超会議のフードコートメニュー14種類紹介（前半）\"\n",
    "print(sentence2index(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 10])\n",
      "tensor([[-0.9143, -0.1806, -1.6063, -2.9259,  0.2443, -0.2509, -1.2115, -0.3370,\n",
      "          0.4518,  0.6813],\n",
      "        [-0.0509, -0.4373,  0.4405,  0.2868, -0.8308, -0.0833, -0.8327,  1.7456,\n",
      "         -1.9794,  0.4105],\n",
      "        [ 1.5419,  0.4190, -0.8487,  1.2749,  0.1685, -0.7368, -1.0076, -0.3328,\n",
      "          1.0134, -0.1921],\n",
      "        [ 0.6678,  0.6699,  1.6113, -0.8781, -0.3092,  0.2965,  1.6885, -0.9035,\n",
      "         -1.5635,  1.1816],\n",
      "        [-0.5977,  0.5126, -0.4317,  0.2213,  0.3638, -1.2196, -2.6224,  0.7957,\n",
      "          1.2390,  0.3384],\n",
      "        [ 1.2144,  0.2597,  0.0264, -0.4244, -0.3945,  1.4334,  1.1210,  1.8455,\n",
      "          0.9255,  0.0069],\n",
      "        [-0.2771, -0.2356, -0.1652, -0.8067,  1.0846, -0.6054,  1.8549,  0.5579,\n",
      "          1.7049, -1.3507],\n",
      "        [-0.4467, -1.5364,  0.2483, -0.2045,  2.8171,  1.0387,  1.6738, -0.1066,\n",
      "          1.3958, -0.6305],\n",
      "        [-0.0509, -0.4373,  0.4405,  0.2868, -0.8308, -0.0833, -0.8327,  1.7456,\n",
      "         -1.9794,  0.4105],\n",
      "        [ 1.3193, -1.8586, -1.1047,  0.4740, -0.8891,  0.8972, -0.4464,  1.6442,\n",
      "          1.7674, -0.9161],\n",
      "        [ 0.2753, -0.9107,  0.8149, -1.8807,  0.1963, -0.5357,  0.6205,  0.6276,\n",
      "          1.5947, -0.3212],\n",
      "        [ 0.3195, -0.7072,  1.2993, -0.5562,  0.3503, -1.5879,  0.3364, -1.3206,\n",
      "         -0.6771,  1.3247],\n",
      "        [-0.8570,  0.9010, -0.4141,  1.2306,  0.0502,  0.9729, -0.3471,  0.9710,\n",
      "         -1.0434, -0.7561]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 全単語数を取得\n",
    "VOCAB_SIZE = len(word2index)\n",
    "# 単語のベクトル数\n",
    "EMBEDDING_DIM = 10\n",
    "test = \"ユージの前に立ちはだかったJOY「僕はAKBの高橋みなみを守る」\"\n",
    "# 単語IDの系列データに変換\n",
    "inputs = sentence2index(test)\n",
    "# 各単語のベクトルをまとめて取得\n",
    "embeds = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "sentence_matrix = embeds(inputs)\n",
    "print(sentence_matrix.size())\n",
    "print(sentence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_matrix.view(len(sentence_matrix), 1, -1).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['震災', 'を', 'うけ', 'て', '感じ', 'た', '大切', 'だ', 'と', '思っ', 'た', 'こと']\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(word2index)\n",
    "EMBEDDING_DIM = 10\n",
    "HIDDEN_DIM = 128\n",
    "embeds = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "lstm = nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM)\n",
    "s1 = \"震災をうけて感じた、大切だと思ったこと\"\n",
    "print(make_wakati(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0757,  0.0145,  0.0848,  ..., -0.0636, -0.0694,  0.1080]],\n",
      "\n",
      "        [[ 0.0858, -0.0606,  0.0393,  ..., -0.0643, -0.0305, -0.0130]],\n",
      "\n",
      "        [[ 0.0077, -0.0261, -0.0271,  ..., -0.0187,  0.0468,  0.0153]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0909,  0.0370,  0.0194,  ..., -0.1056, -0.0623,  0.0614]],\n",
      "\n",
      "        [[ 0.1385, -0.0281,  0.0144,  ..., -0.1064, -0.0226,  0.0555]],\n",
      "\n",
      "        [[ 0.1375, -0.0401,  0.0912,  ..., -0.0580,  0.0312,  0.0665]]],\n",
      "       grad_fn=<StackBackward>)\n",
      "(tensor([[[ 0.1375, -0.0401,  0.0912, -0.0070, -0.0238,  0.0989, -0.0046,\n",
      "          -0.0306,  0.0589, -0.0304,  0.0260, -0.0839,  0.0114,  0.0378,\n",
      "          -0.0429, -0.0273, -0.0084,  0.0610, -0.0340, -0.0756,  0.0284,\n",
      "           0.0338,  0.0233,  0.0076,  0.0546, -0.0148,  0.0405, -0.0275,\n",
      "           0.0451, -0.0789, -0.0369, -0.0645, -0.0319, -0.0223, -0.0383,\n",
      "          -0.0057, -0.1271,  0.0531, -0.0184, -0.0029,  0.1171, -0.0150,\n",
      "          -0.0720,  0.0564,  0.0305, -0.0508,  0.0329,  0.0389,  0.0616,\n",
      "           0.0444,  0.0042,  0.0854,  0.0869, -0.0089, -0.0342,  0.0327,\n",
      "           0.0635,  0.0372,  0.1450,  0.0179,  0.0028,  0.1345,  0.0219,\n",
      "          -0.0229, -0.1156, -0.0621,  0.0258, -0.0465, -0.0216, -0.0267,\n",
      "          -0.0098,  0.0357, -0.0021, -0.0279,  0.0572,  0.0974,  0.0025,\n",
      "           0.0936, -0.0937,  0.0160, -0.0154, -0.0221,  0.0689, -0.0441,\n",
      "           0.0586, -0.0672,  0.0035, -0.1376, -0.0844, -0.1105,  0.0749,\n",
      "          -0.0552,  0.0682, -0.0626,  0.0593, -0.0333, -0.0152, -0.0418,\n",
      "          -0.0831,  0.0957,  0.0311, -0.0059, -0.0400,  0.0381,  0.0374,\n",
      "          -0.0117, -0.1008, -0.0379, -0.0043,  0.0341, -0.0550,  0.0041,\n",
      "          -0.0691,  0.0355, -0.0090, -0.0670, -0.0510, -0.0504, -0.0659,\n",
      "          -0.0043,  0.0598, -0.0139, -0.0579, -0.0799,  0.0299, -0.0580,\n",
      "           0.0312,  0.0665]]], grad_fn=<StackBackward>), tensor([[[ 0.2756, -0.0913,  0.1757, -0.0128, -0.0590,  0.1807, -0.0094,\n",
      "          -0.0590,  0.1300, -0.0632,  0.0530, -0.1730,  0.0216,  0.0774,\n",
      "          -0.0814, -0.0607, -0.0191,  0.1121, -0.0564, -0.1511,  0.0468,\n",
      "           0.0733,  0.0421,  0.0146,  0.1002, -0.0358,  0.0801, -0.0580,\n",
      "           0.0834, -0.1750, -0.0704, -0.1374, -0.0623, -0.0415, -0.0748,\n",
      "          -0.0096, -0.2703,  0.0952, -0.0378, -0.0055,  0.2421, -0.0292,\n",
      "          -0.1502,  0.1266,  0.0567, -0.1065,  0.0719,  0.0828,  0.1390,\n",
      "           0.0923,  0.0092,  0.1636,  0.1977, -0.0199, -0.0728,  0.0809,\n",
      "           0.1417,  0.0922,  0.2903,  0.0392,  0.0059,  0.2376,  0.0439,\n",
      "          -0.0416, -0.2236, -0.1249,  0.0514, -0.0967, -0.0425, -0.0577,\n",
      "          -0.0193,  0.0768, -0.0041, -0.0682,  0.1239,  0.2025,  0.0048,\n",
      "           0.2046, -0.1884,  0.0286, -0.0305, -0.0474,  0.1306, -0.0822,\n",
      "           0.1284, -0.1406,  0.0070, -0.2578, -0.1854, -0.2253,  0.1350,\n",
      "          -0.1227,  0.1335, -0.1202,  0.1275, -0.0679, -0.0279, -0.0815,\n",
      "          -0.1719,  0.1867,  0.0547, -0.0114, -0.0906,  0.0743,  0.0741,\n",
      "          -0.0233, -0.2149, -0.0852, -0.0097,  0.0750, -0.1183,  0.0097,\n",
      "          -0.1459,  0.0746, -0.0170, -0.1440, -0.0964, -0.1124, -0.1556,\n",
      "          -0.0084,  0.1207, -0.0281, -0.1275, -0.1723,  0.0652, -0.1121,\n",
      "           0.0575,  0.1254]]], grad_fn=<StackBackward>))\n"
     ]
    }
   ],
   "source": [
    "inputs1 = sentence2index(s1)\n",
    "emb1 = embeds(inputs1)\n",
    "lstm_inputs1 = emb1.view(len(inputs1), 1, -1)\n",
    "out1, out2 = lstm(lstm_inputs1)\n",
    "print(out1)\n",
    "print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Moduleを継承して新しいクラスを作る。決まり文句\n",
    "class LSTMClassifier(nn.Module):\n",
    "    # モデルで使う各ネットワークをコンストラクタで定義\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        # 親クラスのコンストラクタ。決まり文句\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # インプットの単語をベクトル化するために使う\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # LSTMの隠れ層。これ１つでOK。超便利。\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        # softmaxのLog版。dim=0で列、dim=1で行方向を確率変換。\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    # 順伝播処理はforward関数に記載\n",
    "    def forward(self, sentence):\n",
    "        # 文章内の各単語をベクトル化して出力。2次元のテンソル\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        # 2次元テンソルをLSTMに食わせられる様にviewで３次元テンソルにした上でLSTMへ流す。\n",
    "        # 上記で説明した様にmany to oneのタスクを解きたいので、第二戻り値だけ使う。\n",
    "        _, lstm_out = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        # lstm_out[0]は３次元テンソルになってしまっているので2次元に調整して全結合。\n",
    "        tag_space = self.hidden2tag(lstm_out[0].view(-1, self.hidden_dim))\n",
    "        # softmaxに食わせて、確率として表現\n",
    "        tag_scores = self.softmax(tag_space)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 正解ラベルの変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dokujo-tsushin': 0, 'it-life-hack': 1, 'kaden-channel': 2, 'livedoor-homme': 3, 'movie-enter': 4, 'peachy': 5, 'smax': 6, 'sports-watch': 7, 'topic-news': 8}\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "category2index = {}\n",
    "for cat in categories:\n",
    "    if cat in category2index: continue\n",
    "    category2index[cat] = len(category2index)\n",
    "print(category2index)\n",
    "\n",
    "def category2tensor(cat):\n",
    "    return torch.tensor([category2index[cat]], dtype=torch.long)\n",
    "\n",
    "print(category2tensor(\"it-life-hack\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 \t loss 10837.927973091602\n",
      "epoch 1 \t loss 9850.494552783668\n",
      "epoch 2 \t loss 9202.383053142577\n",
      "epoch 3 \t loss 8641.099359605461\n",
      "epoch 4 \t loss 8091.073602993973\n",
      "epoch 5 \t loss 7548.26091079833\n",
      "epoch 6 \t loss 7043.689604850486\n",
      "epoch 7 \t loss 6574.085030316142\n",
      "epoch 8 \t loss 6121.265577514423\n",
      "epoch 9 \t loss 5684.06743454875\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "# 元データを7:3に分ける（7->学習、3->テスト）\n",
    "traindata, testdata = train_test_split(datasets, train_size=0.7)\n",
    "\n",
    "# 単語のベクトル次元数\n",
    "EMBEDDING_DIM = 10\n",
    "# 隠れ層の次元数\n",
    "HIDDEN_DIM = 128\n",
    "# データ全体の単語数\n",
    "VOCAB_SIZE = len(word2index)\n",
    "# 分類先のカテゴリの数\n",
    "TAG_SIZE = len(categories)\n",
    "# モデル宣言\n",
    "model = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TAG_SIZE)\n",
    "# 損失関数はNLLLoss()を使う。LogSoftmaxを使う時はこれを使うらしい。\n",
    "loss_function = nn.NLLLoss()\n",
    "# 最適化の手法はSGDで。lossの減りに時間かかるけど、一旦はこれを使う。\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 各エポックの合計loss値を格納する\n",
    "losses = []\n",
    "# 10ループ回してみる。（バッチ化とかGPU使ってないので結構時間かかる...）\n",
    "for epoch in range(10):\n",
    "    all_loss = 0\n",
    "    for title, cat in zip(traindata[\"title\"], traindata[\"category\"]):\n",
    "        # モデルが持ってる勾配の情報をリセット\n",
    "        model.zero_grad()\n",
    "        # 文章を単語IDの系列に変換（modelに食わせられる形に変換）\n",
    "        inputs = sentence2index(title)\n",
    "        # 順伝播の結果を受け取る\n",
    "        out = model(inputs)\n",
    "        # 正解カテゴリをテンソル化\n",
    "        answer = category2tensor(cat)\n",
    "        # 正解とのlossを計算\n",
    "        loss = loss_function(out, answer)\n",
    "        # 勾配をセット\n",
    "        loss.backward()\n",
    "        # 逆伝播でパラメータ更新\n",
    "        optimizer.step()\n",
    "        # lossを集計\n",
    "        all_loss += loss.item()\n",
    "    losses.append(all_loss)\n",
    "    print(\"epoch\", epoch, \"\\t\" , \"loss\", all_loss)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb91e87b6d0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 予測精度確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict :  0.5603253502033438\n"
     ]
    }
   ],
   "source": [
    "# テストデータの母数計算\n",
    "test_num = len(testdata)\n",
    "# 正解の件数\n",
    "a = 0\n",
    "# 勾配自動計算OFF\n",
    "with torch.no_grad():\n",
    "    for title, category in zip(testdata[\"title\"], testdata[\"category\"]):\n",
    "        # テストデータの予測\n",
    "        inputs = sentence2index(title)\n",
    "        out = model(inputs)\n",
    "\n",
    "        # outの一番大きい要素を予測結果をする\n",
    "        _, predict = torch.max(out, 1)\n",
    "\n",
    "        answer = category2tensor(category)\n",
    "        if predict == answer:\n",
    "            a += 1\n",
    "print(\"predict : \", a / test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 過学習の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict :  0.6505907418167732\n"
     ]
    }
   ],
   "source": [
    "traindata_num = len(traindata)\n",
    "a = 0\n",
    "with torch.no_grad():\n",
    "    for title, category in zip(traindata[\"title\"], traindata[\"category\"]):\n",
    "        inputs = sentence2index(title)\n",
    "        out = model(inputs)\n",
    "        _, predict = torch.max(out, 1)\n",
    "        answer = category2tensor(category)\n",
    "        if predict == answer:\n",
    "            a += 1\n",
    "print(\"predict : \", a / traindata_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fスコアの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         category  all  precison  recall  fscore\n",
      "0  dokujo-tsushin  255      0.57    0.65    0.61\n",
      "1    it-life-hack  263      0.76    0.57    0.65\n",
      "2   kaden-channel  281      0.88    0.72    0.79\n",
      "3  livedoor-homme  137      0.51    0.45    0.47\n",
      "4     movie-enter  281      0.33    0.43    0.37\n",
      "5          peachy  259      0.53    0.40    0.46\n",
      "6            smax  243      0.72    0.87    0.79\n",
      "7    sports-watch  270      0.45    0.33    0.38\n",
      "8      topic-news  224      0.42    0.60    0.49\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "# IDをカテゴリに戻す用\n",
    "index2category = {}\n",
    "for cat, idx in category2index.items():\n",
    "    index2category[idx] = cat\n",
    "\n",
    "# answer -> 正解ラベル、predict->LSTMの予測結果、exact->正解してたらO,間違っていたらX\n",
    "predict_df = pd.DataFrame(columns=[\"answer\", \"predict\", \"exact\"])\n",
    "\n",
    "# 予測して結果を上のDFに格納\n",
    "with torch.no_grad():\n",
    "    for title, category in zip(testdata[\"title\"], testdata[\"category\"]):\n",
    "        out = model(sentence2index(title))\n",
    "        _, predict = torch.max(out, 1)\n",
    "        answer = category2tensor(category)\n",
    "        exact = \"O\" if predict.item() == answer.item() else \"X\"\n",
    "        s = pd.Series([answer.item(), predict.item(), exact], index=predict_df.columns)\n",
    "        predict_df = predict_df.append(s, ignore_index=True)\n",
    "\n",
    "# Fスコア格納用のDF\n",
    "fscore_df = pd.DataFrame(columns=[\"category\", \"all\",\"precison\", \"recall\", \"fscore\"])\n",
    "\n",
    "# 分類器が答えた各カテゴリの件数\n",
    "prediction_count = collections.Counter(predict_df[\"predict\"])\n",
    "# 各カテゴリの総件数\n",
    "answer_count = collections.Counter(predict_df[\"answer\"])\n",
    "\n",
    "# Fスコア求める\n",
    "for i in range(9):\n",
    "    all_count = answer_count[i]\n",
    "    precision = len(predict_df.query('predict == ' + str(i) + ' and exact == \"O\"')) / prediction_count[i]\n",
    "    recall = len(predict_df.query('answer == ' + str(i) + ' and exact == \"O\"')) / all_count\n",
    "    fscore = 2*precision*recall / (precision + recall)\n",
    "    s = pd.Series([index2category[i], all_count, round(precision, 2), round(recall, 2), round(fscore, 2)], index=fscore_df.columns)\n",
    "    fscore_df = fscore_df.append(s, ignore_index=True)\n",
    "print(fscore_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
