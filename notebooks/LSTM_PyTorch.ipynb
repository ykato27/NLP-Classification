{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorchを使ってLSTMで文章分類を実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データ準備\n",
    "livedoorニュースコーパスの「ldcc-20140209.tar.gz」データをダウンロードします。\n",
    "https://www.rondhuit.com/download.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データフレーム作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dokujo-tsushin', 'it-life-hack', 'kaden-channel', 'livedoor-homme', 'movie-enter', 'peachy', 'smax', 'sports-watch', 'topic-news']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import linecache\n",
    "\n",
    "# カテゴリを配列で取得\n",
    "categories = [name for name in os.listdir(\"text\") if os.path.isdir(\"text/\" + name)]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>女子力を下げる！？ ブラトップのメリット・デメリット\\n</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60歳のリーアム・ニーソンが大自然に挑む！　全米初登場1位を獲得した話題作の特別映像が公開\\n</td>\n",
       "      <td>movie-enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>清水エスパルス、ラフプレー連発の韓国チームとの試合打ち切り\\n</td>\n",
       "      <td>sports-watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>【週末映画まとめ読み】川口春奈の学校の呪いか、怪奇現象が撮影スタッフを襲う\\n</td>\n",
       "      <td>movie-enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>応援する？ ムカつく？ あなたの近くの社内恋愛\\n</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title        category\n",
       "0                     女子力を下げる！？ ブラトップのメリット・デメリット\\n  dokujo-tsushin\n",
       "1  60歳のリーアム・ニーソンが大自然に挑む！　全米初登場1位を獲得した話題作の特別映像が公開\\n     movie-enter\n",
       "2                  清水エスパルス、ラフプレー連発の韓国チームとの試合打ち切り\\n    sports-watch\n",
       "3          【週末映画まとめ読み】川口春奈の学校の呪いか、怪奇現象が撮影スタッフを襲う\\n     movie-enter\n",
       "4                        応援する？ ムカつく？ あなたの近くの社内恋愛\\n  dokujo-tsushin"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = pd.DataFrame(columns=[\"title\", \"category\"])\n",
    "for cat in categories:\n",
    "    path = \"text/\" + cat + \"/*.txt\"\n",
    "    files = glob(path)\n",
    "    for text_name in files:\n",
    "        title = linecache.getline(text_name, 3)\n",
    "        s = pd.Series([title, cat], index=datasets.columns)\n",
    "        datasets = datasets.append(s, ignore_index=True)\n",
    "\n",
    "# データフレームシャッフル\n",
    "datasets = datasets.sample(frac=1).reset_index(drop=True)\n",
    "datasets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### インプットデータの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0034, -1.0937, -0.8714, -0.6852, -1.8119, -1.0698]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[-0.0034, -1.0937, -0.8714, -0.6852, -1.8119, -1.0698],\n",
      "        [-1.0718, -1.6312, -1.0900,  0.2803,  0.5652,  0.3648],\n",
      "        [ 1.5000,  0.5839, -1.7280,  0.8511, -0.1485,  0.2626]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 以下の宣言で行が単語ベクトル、列が単語のインデックスのマトリクスを生成してる感じ\n",
    "embeds = nn.Embedding(10, 6)  # (Embedding(単語の合計数, ベクトル次元数))\n",
    "\n",
    "# ３行目の要素を取り出したいならば\n",
    "w1 = torch.tensor([2])\n",
    "print(embeds(w1))\n",
    "# tensor([[-1.5947, -0.8387,  0.7669, -0.9644, -0.7902,  2.7167]],\n",
    "#        grad_fn=<EmbeddingBackward>)\n",
    "\n",
    "# 3行目、5行目、１０行目の要素を取り出したいならば、\n",
    "w2 = torch.tensor([2, 4, 9])\n",
    "print(embeds(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['人工', '知能', 'は', '人間', 'の', '仕事', 'を', '奪っ', 'た']\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "import re\n",
    "import torch\n",
    "\n",
    "tagger = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "\n",
    "def make_wakati(sentence):\n",
    "    # MeCabで分かち書き\n",
    "    sentence = tagger.parse(sentence)\n",
    "    # 半角全角英数字除去\n",
    "    sentence = re.sub(r\"[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+\", \" \", sentence)\n",
    "    # 記号もろもろ除去\n",
    "    sentence = re.sub(\n",
    "        r\"[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+\",\n",
    "        \"\",\n",
    "        sentence,\n",
    "    )\n",
    "    # スペースで区切って形態素の配列へ\n",
    "    wakati = sentence.split(\" \")\n",
    "    # 空の要素は削除\n",
    "    wakati = list(filter((\"\").__ne__, wakati))\n",
    "    return wakati\n",
    "\n",
    "\n",
    "# テスト\n",
    "test = \"【人工知能】は「人間」の仕事を奪った\"\n",
    "print(make_wakati(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size :  12943\n",
      "tensor([11146,     5,   510,  1791,    87,   455,   579,   117,     5,  6609,\n",
      "         9441,  1791,   139,   226,  8867])\n"
     ]
    }
   ],
   "source": [
    "# 単語ID辞書を作成する\n",
    "word2index = {}\n",
    "for title in datasets[\"title\"]:\n",
    "    wakati = make_wakati(title)\n",
    "    for word in wakati:\n",
    "        if word in word2index:\n",
    "            continue\n",
    "        word2index[word] = len(word2index)\n",
    "print(\"vocab size : \", len(word2index))\n",
    "\n",
    "# 文章を単語IDの系列データに変換\n",
    "# PyTorchのLSTMのインプットになるデータなので、もちろんtensor型で\n",
    "def sentence2index(sentence):\n",
    "    wakati = make_wakati(sentence)\n",
    "    return torch.tensor([word2index[w] for w in wakati], dtype=torch.long)\n",
    "\n",
    "\n",
    "# テスト\n",
    "test = \"例のあのメニューも！ニコニコ超会議のフードコートメニュー14種類紹介（前半）\"\n",
    "print(sentence2index(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 10])\n",
      "tensor([[ 1.2924,  1.0049, -0.4235, -0.3145, -0.2015,  0.2303, -1.5611,  0.7944,\n",
      "         -1.5076, -0.8984],\n",
      "        [ 2.7855,  1.5174, -1.6479, -0.6083,  1.1645,  0.0814, -0.4043, -0.9885,\n",
      "          0.3231,  0.0576],\n",
      "        [-0.2359,  0.6628, -0.7361, -1.0698, -0.0396, -0.6841, -0.7214, -1.3837,\n",
      "         -0.1436,  1.3037],\n",
      "        [-0.2570, -0.7394, -1.4081,  0.1961, -0.3433,  0.0773,  1.6191,  2.7852,\n",
      "         -1.3463, -0.2776],\n",
      "        [ 0.9059, -1.1631, -0.6054,  2.1713,  0.2681,  1.3946,  1.3794, -1.0091,\n",
      "         -1.4485,  0.3529],\n",
      "        [ 0.6158,  0.2263,  2.4530,  1.4154, -0.3832,  0.8459,  0.8830,  1.0365,\n",
      "          0.6138, -1.1633],\n",
      "        [ 0.7098,  1.5520,  1.6125,  0.2795,  1.0094, -2.2304, -0.5424,  1.6241,\n",
      "          0.3676, -0.0075],\n",
      "        [-1.5199, -1.4179, -1.1198, -1.3027,  0.4719, -1.0985, -0.6489,  0.7052,\n",
      "         -0.1862,  1.9341],\n",
      "        [ 2.7855,  1.5174, -1.6479, -0.6083,  1.1645,  0.0814, -0.4043, -0.9885,\n",
      "          0.3231,  0.0576],\n",
      "        [ 3.1440,  1.0042,  0.5621, -1.8985, -0.2490, -1.3089, -1.4924,  2.0114,\n",
      "          0.6218,  0.1814],\n",
      "        [-0.5909, -1.6925,  0.5677, -1.3371, -0.0907,  0.0845,  1.0076, -0.1504,\n",
      "         -1.2118,  0.7135],\n",
      "        [ 0.6556,  0.9722, -0.3813,  0.0975, -0.2587,  2.0446,  0.0325,  0.6310,\n",
      "          0.0890,  0.8192],\n",
      "        [ 0.0791, -0.3671, -0.3946, -1.0270, -0.5004, -0.2732,  0.8877, -0.7449,\n",
      "         -0.1507, -1.4660]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 全単語数を取得\n",
    "VOCAB_SIZE = len(word2index)\n",
    "# 単語のベクトル数\n",
    "EMBEDDING_DIM = 10\n",
    "test = \"ユージの前に立ちはだかったJOY「僕はAKBの高橋みなみを守る」\"\n",
    "# 単語IDの系列データに変換\n",
    "inputs = sentence2index(test)\n",
    "# 各単語のベクトルをまとめて取得\n",
    "embeds = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "sentence_matrix = embeds(inputs)\n",
    "print(sentence_matrix.size())\n",
    "print(sentence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_matrix.view(len(sentence_matrix), 1, -1).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['震災', 'を', 'うけ', 'て', '感じ', 'た', '大切', 'だ', 'と', '思っ', 'た', 'こと']\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(word2index)\n",
    "EMBEDDING_DIM = 10\n",
    "HIDDEN_DIM = 128\n",
    "embeds = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "lstm = nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM)\n",
    "s1 = \"震災をうけて感じた、大切だと思ったこと\"\n",
    "print(make_wakati(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0128,  0.0267,  0.0776,  ..., -0.0112,  0.0140,  0.0113]],\n",
      "\n",
      "        [[-0.0264,  0.0674,  0.1119,  ..., -0.0416, -0.0032,  0.0505]],\n",
      "\n",
      "        [[-0.0053,  0.0437,  0.1291,  ..., -0.0072,  0.0328, -0.0062]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0551,  0.0038,  0.0182,  ...,  0.0249,  0.0209, -0.0449]],\n",
      "\n",
      "        [[ 0.1119,  0.0309, -0.0194,  ..., -0.0072, -0.0141,  0.0214]],\n",
      "\n",
      "        [[ 0.1313,  0.0005,  0.0278,  ...,  0.0137,  0.0589,  0.0211]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "(tensor([[[ 1.3127e-01,  4.7330e-04,  2.7796e-02, -7.9767e-02,  5.1947e-02,\n",
      "          -4.5127e-02, -6.4936e-02,  8.7204e-02, -3.8702e-03, -3.8706e-02,\n",
      "          -6.3807e-02,  6.5902e-02, -2.4949e-02,  8.3646e-02, -6.3064e-02,\n",
      "          -1.0602e-01,  3.8388e-05,  6.8999e-02,  4.0204e-02, -8.6478e-03,\n",
      "          -2.7997e-02,  5.8894e-02,  5.8136e-02,  5.6753e-02, -9.4914e-02,\n",
      "           4.6531e-03,  7.7826e-02, -3.4170e-02, -7.5847e-02,  3.3081e-02,\n",
      "           4.5665e-02,  6.9231e-02,  5.7566e-02, -9.7086e-03,  4.5250e-02,\n",
      "          -2.7253e-02, -7.1551e-02,  3.2714e-02,  3.7147e-02,  2.4832e-02,\n",
      "          -1.9405e-02, -3.1688e-02,  3.9427e-02,  5.3601e-02,  5.2349e-03,\n",
      "           5.0764e-02, -1.5462e-02,  4.5652e-02, -4.0091e-02, -4.0381e-02,\n",
      "           1.0862e-01,  7.7230e-03, -1.3595e-02,  3.1126e-02, -4.8445e-02,\n",
      "          -1.9797e-02,  2.6548e-02,  3.9553e-02,  6.4008e-02, -9.4711e-02,\n",
      "           4.9239e-02,  3.5678e-02,  1.3752e-02,  1.5067e-01,  1.3298e-03,\n",
      "          -7.0645e-02,  5.9583e-02,  5.8131e-02,  1.0833e-01,  3.0180e-02,\n",
      "           3.6855e-02,  1.1172e-02, -4.4471e-05,  3.9735e-02,  1.6739e-02,\n",
      "           3.3633e-03, -2.4313e-02,  1.3614e-02, -2.2227e-02,  5.9530e-02,\n",
      "          -1.3639e-02,  8.9830e-03, -3.2634e-02, -4.8858e-02, -8.3744e-02,\n",
      "           7.8117e-02,  4.9688e-03,  1.4055e-02,  5.4306e-02,  3.3536e-02,\n",
      "           3.4316e-02,  7.0889e-02,  2.8314e-02, -2.5754e-02, -2.7078e-02,\n",
      "           1.9537e-02,  3.2624e-02,  3.3807e-02,  1.3330e-02, -5.3879e-02,\n",
      "          -2.8655e-02,  3.7005e-02,  2.6805e-02, -4.8211e-02,  2.0007e-02,\n",
      "          -3.7759e-02, -5.9281e-02,  2.5213e-02,  2.1711e-04, -1.8524e-02,\n",
      "          -4.4987e-02,  2.9940e-02, -2.1676e-02,  5.6322e-02,  3.8246e-02,\n",
      "           5.4314e-02,  3.5558e-02, -3.5103e-03, -4.3267e-03, -8.3244e-02,\n",
      "           4.0747e-02, -3.4511e-02, -6.0334e-02,  3.3158e-02, -5.2675e-02,\n",
      "           1.3708e-02,  5.8869e-02,  2.1112e-02]]], grad_fn=<StackBackward0>), tensor([[[ 2.4145e-01,  9.4291e-04,  6.1038e-02, -1.5387e-01,  1.0838e-01,\n",
      "          -9.1525e-02, -1.1832e-01,  1.5238e-01, -8.0308e-03, -7.1690e-02,\n",
      "          -1.5718e-01,  1.2691e-01, -5.1523e-02,  1.6826e-01, -1.2290e-01,\n",
      "          -2.1728e-01,  7.9967e-05,  1.4001e-01,  7.6196e-02, -1.6586e-02,\n",
      "          -7.3809e-02,  1.1138e-01,  1.0655e-01,  1.1083e-01, -1.7587e-01,\n",
      "           9.8429e-03,  1.6878e-01, -7.4704e-02, -1.6362e-01,  6.4957e-02,\n",
      "           8.6391e-02,  1.4450e-01,  1.0310e-01, -1.8632e-02,  7.9944e-02,\n",
      "          -5.7905e-02, -1.4545e-01,  7.1170e-02,  7.4027e-02,  4.7603e-02,\n",
      "          -4.2178e-02, -6.7923e-02,  8.2054e-02,  1.2941e-01,  1.0829e-02,\n",
      "           1.0307e-01, -3.5899e-02,  9.2380e-02, -7.4226e-02, -7.8153e-02,\n",
      "           1.9394e-01,  1.4785e-02, -2.6032e-02,  6.2448e-02, -9.4313e-02,\n",
      "          -3.7358e-02,  4.9946e-02,  8.2290e-02,  1.5074e-01, -1.8484e-01,\n",
      "           8.9762e-02,  7.4094e-02,  2.7618e-02,  2.8581e-01,  2.6376e-03,\n",
      "          -1.2540e-01,  1.1356e-01,  1.2149e-01,  2.0926e-01,  6.2464e-02,\n",
      "           6.9162e-02,  2.5580e-02, -8.9258e-05,  7.5724e-02,  3.1527e-02,\n",
      "           6.7042e-03, -5.0766e-02,  2.6218e-02, -4.7683e-02,  1.0857e-01,\n",
      "          -2.8034e-02,  1.5536e-02, -6.5689e-02, -1.0042e-01, -1.7086e-01,\n",
      "           1.5473e-01,  9.8188e-03,  2.5380e-02,  1.0588e-01,  6.8934e-02,\n",
      "           7.2896e-02,  1.4955e-01,  5.7929e-02, -5.2951e-02, -5.7266e-02,\n",
      "           4.1192e-02,  6.6713e-02,  6.9333e-02,  2.5351e-02, -1.2180e-01,\n",
      "          -5.6119e-02,  7.8128e-02,  5.3596e-02, -8.6238e-02,  3.8304e-02,\n",
      "          -7.7802e-02, -1.1723e-01,  5.3834e-02,  4.8798e-04, -3.7957e-02,\n",
      "          -7.9853e-02,  6.3533e-02, -4.4052e-02,  1.1110e-01,  8.4962e-02,\n",
      "           1.1486e-01,  6.9329e-02, -6.9402e-03, -7.5484e-03, -1.5773e-01,\n",
      "           8.5199e-02, -6.9194e-02, -1.1517e-01,  6.6768e-02, -1.0739e-01,\n",
      "           3.1290e-02,  1.2133e-01,  4.0761e-02]]], grad_fn=<StackBackward0>))\n"
     ]
    }
   ],
   "source": [
    "inputs1 = sentence2index(s1)\n",
    "emb1 = embeds(inputs1)\n",
    "lstm_inputs1 = emb1.view(len(inputs1), 1, -1)\n",
    "out1, out2 = lstm(lstm_inputs1)\n",
    "print(out1)\n",
    "print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Moduleを継承して新しいクラスを作る。決まり文句\n",
    "class LSTMClassifier(nn.Module):\n",
    "    # モデルで使う各ネットワークをコンストラクタで定義\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        # 親クラスのコンストラクタ。決まり文句\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # インプットの単語をベクトル化するために使う\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # LSTMの隠れ層。これ１つでOK。超便利。\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        # softmaxのLog版。dim=0で列、dim=1で行方向を確率変換。\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    # 順伝播処理はforward関数に記載\n",
    "    def forward(self, sentence):\n",
    "        # 文章内の各単語をベクトル化して出力。2次元のテンソル\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        # 2次元テンソルをLSTMに食わせられる様にviewで３次元テンソルにした上でLSTMへ流す。\n",
    "        # 上記で説明した様にmany to oneのタスクを解きたいので、第二戻り値だけ使う。\n",
    "        _, lstm_out = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        # lstm_out[0]は３次元テンソルになってしまっているので2次元に調整して全結合。\n",
    "        tag_space = self.hidden2tag(lstm_out[0].view(-1, self.hidden_dim))\n",
    "        # softmaxに食わせて、確率として表現\n",
    "        tag_scores = self.softmax(tag_space)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 正解ラベルの変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dokujo-tsushin': 0, 'it-life-hack': 1, 'kaden-channel': 2, 'livedoor-homme': 3, 'movie-enter': 4, 'peachy': 5, 'smax': 6, 'sports-watch': 7, 'topic-news': 8}\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "category2index = {}\n",
    "for cat in categories:\n",
    "    if cat in category2index:\n",
    "        continue\n",
    "    category2index[cat] = len(category2index)\n",
    "print(category2index)\n",
    "\n",
    "\n",
    "def category2tensor(cat):\n",
    "    return torch.tensor([category2index[cat]], dtype=torch.long)\n",
    "\n",
    "\n",
    "print(category2tensor(\"it-life-hack\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 \t loss 10927.646444737911\n",
      "epoch 1 \t loss 10020.675048947334\n",
      "epoch 2 \t loss 9456.020045340061\n",
      "epoch 3 \t loss 8970.832570170984\n",
      "epoch 4 \t loss 8431.61981849838\n",
      "epoch 5 \t loss 7906.497477673693\n",
      "epoch 6 \t loss 7426.976272659202\n",
      "epoch 7 \t loss 6985.692273202003\n",
      "epoch 8 \t loss 6570.234288050502\n",
      "epoch 9 \t loss 6175.362874631945\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "\n",
    "# 元データを7:3に分ける（7->学習、3->テスト）\n",
    "traindata, testdata = train_test_split(datasets, train_size=0.7)\n",
    "\n",
    "# 単語のベクトル次元数\n",
    "EMBEDDING_DIM = 10\n",
    "# 隠れ層の次元数\n",
    "HIDDEN_DIM = 128\n",
    "# データ全体の単語数\n",
    "VOCAB_SIZE = len(word2index)\n",
    "# 分類先のカテゴリの数\n",
    "TAG_SIZE = len(categories)\n",
    "# モデル宣言\n",
    "model = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TAG_SIZE)\n",
    "# 損失関数はNLLLoss()を使う。LogSoftmaxを使う時はこれを使うらしい。\n",
    "loss_function = nn.NLLLoss()\n",
    "# 最適化の手法はSGDで。lossの減りに時間かかるけど、一旦はこれを使う。\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 各エポックの合計loss値を格納する\n",
    "losses = []\n",
    "# 10ループ回してみる。（バッチ化とかGPU使ってないので結構時間かかる...）\n",
    "for epoch in range(10):\n",
    "    all_loss = 0\n",
    "    for title, cat in zip(traindata[\"title\"], traindata[\"category\"]):\n",
    "        # モデルが持ってる勾配の情報をリセット\n",
    "        model.zero_grad()\n",
    "        # 文章を単語IDの系列に変換（modelに食わせられる形に変換）\n",
    "        inputs = sentence2index(title)\n",
    "        # 順伝播の結果を受け取る\n",
    "        out = model(inputs)\n",
    "        # 正解カテゴリをテンソル化\n",
    "        answer = category2tensor(cat)\n",
    "        # 正解とのlossを計算\n",
    "        loss = loss_function(out, answer)\n",
    "        # 勾配をセット\n",
    "        loss.backward()\n",
    "        # 逆伝播でパラメータ更新\n",
    "        optimizer.step()\n",
    "        # lossを集計\n",
    "        all_loss += loss.item()\n",
    "    losses.append(all_loss)\n",
    "    print(\"epoch\", epoch, \"\\t\", \"loss\", all_loss)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc3eb785a00>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 予測精度確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict :  0.5743334839584274\n"
     ]
    }
   ],
   "source": [
    "# テストデータの母数計算\n",
    "test_num = len(testdata)\n",
    "# 正解の件数\n",
    "a = 0\n",
    "# 勾配自動計算OFF\n",
    "with torch.no_grad():\n",
    "    for title, category in zip(testdata[\"title\"], testdata[\"category\"]):\n",
    "        # テストデータの予測\n",
    "        inputs = sentence2index(title)\n",
    "        out = model(inputs)\n",
    "\n",
    "        # outの一番大きい要素を予測結果をする\n",
    "        _, predict = torch.max(out, 1)\n",
    "\n",
    "        answer = category2tensor(category)\n",
    "        if predict == answer:\n",
    "            a += 1\n",
    "print(\"predict : \", a / test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 過学習の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict :  0.621537865582026\n"
     ]
    }
   ],
   "source": [
    "traindata_num = len(traindata)\n",
    "a = 0\n",
    "with torch.no_grad():\n",
    "    for title, category in zip(traindata[\"title\"], traindata[\"category\"]):\n",
    "        inputs = sentence2index(title)\n",
    "        out = model(inputs)\n",
    "        _, predict = torch.max(out, 1)\n",
    "        answer = category2tensor(category)\n",
    "        if predict == answer:\n",
    "            a += 1\n",
    "print(\"predict : \", a / traindata_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fスコアの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         category  all  precison  recall  fscore\n",
      "0  dokujo-tsushin  242      0.49    0.64    0.55\n",
      "1    it-life-hack  291      0.65    0.64    0.65\n",
      "2   kaden-channel  245      0.90    0.74    0.81\n",
      "3  livedoor-homme  157      0.59    0.48    0.53\n",
      "4     movie-enter  267      0.41    0.40    0.41\n",
      "5          peachy  244      0.50    0.46    0.48\n",
      "6            smax  263      0.71    0.86    0.78\n",
      "7    sports-watch  270      0.44    0.41    0.43\n",
      "8      topic-news  234      0.52    0.49    0.50\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "# IDをカテゴリに戻す用\n",
    "index2category = {}\n",
    "for cat, idx in category2index.items():\n",
    "    index2category[idx] = cat\n",
    "\n",
    "# answer -> 正解ラベル、predict->LSTMの予測結果、exact->正解してたらO,間違っていたらX\n",
    "predict_df = pd.DataFrame(columns=[\"answer\", \"predict\", \"exact\"])\n",
    "\n",
    "# 予測して結果を上のDFに格納\n",
    "with torch.no_grad():\n",
    "    for title, category in zip(testdata[\"title\"], testdata[\"category\"]):\n",
    "        out = model(sentence2index(title))\n",
    "        _, predict = torch.max(out, 1)\n",
    "        answer = category2tensor(category)\n",
    "        exact = \"O\" if predict.item() == answer.item() else \"X\"\n",
    "        s = pd.Series([answer.item(), predict.item(), exact], index=predict_df.columns)\n",
    "        predict_df = predict_df.append(s, ignore_index=True)\n",
    "\n",
    "# Fスコア格納用のDF\n",
    "fscore_df = pd.DataFrame(columns=[\"category\", \"all\", \"precison\", \"recall\", \"fscore\"])\n",
    "\n",
    "# 分類器が答えた各カテゴリの件数\n",
    "prediction_count = collections.Counter(predict_df[\"predict\"])\n",
    "# 各カテゴリの総件数\n",
    "answer_count = collections.Counter(predict_df[\"answer\"])\n",
    "\n",
    "# Fスコア求める\n",
    "for i in range(9):\n",
    "    all_count = answer_count[i]\n",
    "    precision = (\n",
    "        len(predict_df.query(\"predict == \" + str(i) + ' and exact == \"O\"'))\n",
    "        / prediction_count[i]\n",
    "    )\n",
    "    recall = (\n",
    "        len(predict_df.query(\"answer == \" + str(i) + ' and exact == \"O\"')) / all_count\n",
    "    )\n",
    "    fscore = 2 * precision * recall / (precision + recall)\n",
    "    s = pd.Series(\n",
    "        [\n",
    "            index2category[i],\n",
    "            all_count,\n",
    "            round(precision, 2),\n",
    "            round(recall, 2),\n",
    "            round(fscore, 2),\n",
    "        ],\n",
    "        index=fscore_df.columns,\n",
    "    )\n",
    "    fscore_df = fscore_df.append(s, ignore_index=True)\n",
    "print(fscore_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
