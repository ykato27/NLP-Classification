{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seq2Seqとは\n",
    "Seq2Seq(sequence to sequence)は、以下で説明するEncoderとDecoderを備えたEncoder-Decoderモデルを使って、系列データを別の系列データに変換するモデルのこと"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoderとは\n",
    "InputData(画像、テキスト、音声、動画etc)を何かしらの(固定長)特徴ベクトルに変換する機構のことを言います。\n",
    "そのまんまですが、InputDataを抽象的なベクトルにエンコードしてるイメージ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoderとは\n",
    "Encoderでエンコードされた特徴ベクトルをデコードして何か新しいデータを生む機構のことをいいます。\n",
    "OutputDataはInputDataと同じデータ形式である必要はなく、画像、テキスト、音声いろいろ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder-Decoderモデルとは\n",
    "EncoderとDecoderをつなげると、Encoder-Decoderモデルの完成\n",
    "Encoder-Decoderモデルはいわゆる生成系のモデルであり、画像をテキストにしたり、音声からテキストを生成したり、日本語から英語（テキストから別のテキスト）に変換したりと用途は様々。\n",
    "今回はこのSeq2Seqを使って系列データを別の系列データに変換するモデルを実装を通して解説"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データの準備\n",
    "引き算データセットの準備はどこかから入手する必要もなく、自前で準備すればOK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# 数字の文字をID化\n",
    "char2id = {str(i): i for i in range(10)}\n",
    "\n",
    "# 空白(10)：系列の長さを揃えるようのパディング文字\n",
    "# -(11)：マイナスの文字\n",
    "# _(12)：系列生成開始を知らせる文字\n",
    "char2id.update({\" \": 10, \"-\": 11, \"_\": 12})\n",
    "\n",
    "# 空白込みの３桁の数字をランダムに生成\n",
    "def generate_number():\n",
    "    number = [random.choice(list(\"0123456789\")) for _ in range(random.randint(1, 3))]\n",
    "    return int(\"\".join(number))\n",
    "\n",
    "\n",
    "# 確認\n",
    "print(generate_number())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"212    \"\n"
     ]
    }
   ],
   "source": [
    "# 系列の長さを揃えるために空白パディング\n",
    "def add_padding(number, is_input=True):\n",
    "    number = \"{: <7}\".format(number) if is_input else \"{: <5s}\".format(number)\n",
    "    return number\n",
    "\n",
    "\n",
    "# 確認\n",
    "num = generate_number()\n",
    "print('\"' + str(add_padding(num)) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 2, 11, 8, 10, 10, 10]\n",
      "[12, 7, 4, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "# データ準備\n",
    "input_data = []\n",
    "output_data = []\n",
    "\n",
    "# データを５００００件準備する\n",
    "while len(input_data) < 50000:\n",
    "    x = generate_number()\n",
    "    y = generate_number()\n",
    "    z = x - y\n",
    "    input_char = add_padding(str(x) + \"-\" + str(y))\n",
    "    output_char = add_padding(\"_\" + str(z), is_input=False)\n",
    "\n",
    "    # データをIDにに変換\n",
    "    input_data.append([char2id[c] for c in input_char])\n",
    "    output_data.append([char2id[c] for c in output_char])\n",
    "\n",
    "# 確認\n",
    "print(input_data[987])\n",
    "print(output_data[987])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ７：３にデータをわける\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    input_data, output_data, train_size=0.7\n",
    ")\n",
    "\n",
    "\n",
    "# データをバッチ化するための関数\n",
    "def train2batch(input_data, output_data, batch_size=100):\n",
    "    input_batch = []\n",
    "    output_batch = []\n",
    "    input_shuffle, output_shuffle = shuffle(input_data, output_data)\n",
    "    for i in range(0, len(input_data), batch_size):\n",
    "        input_batch.append(input_shuffle[i : i + batch_size])\n",
    "        output_batch.append(output_shuffle[i : i + batch_size])\n",
    "    return input_batch, output_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モデル定義\n",
    "- Encoder\n",
    "- Encoderは簡単。隠れ層を返すだけでOK。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "embedding_dim = 200  # 文字の埋め込み次元数\n",
    "hidden_dim = 128  # LSTMの隠れ層のサイズ\n",
    "vocab_size = len(char2id)  # 扱う文字の数。今回は１３文字\n",
    "\n",
    "# GPU使う用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Encoderクラス\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(\n",
    "            vocab_size, embedding_dim, padding_idx=char2id[\" \"]\n",
    "        )\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        embedding = self.word_embeddings(sequence)\n",
    "        # Many to Oneなので、第２戻り値を使う\n",
    "        _, state = self.lstm(embedding)\n",
    "        # state = (h, c)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decoder\n",
    "- Decoderの予測値は最大値をそのまま使えばいいので、softmaxは不要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoderクラス\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(\n",
    "            vocab_size, embedding_dim, padding_idx=char2id[\" \"]\n",
    "        )\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        # LSTMの128次元の隠れ層を13次元に変換する全結合層\n",
    "        self.hidden2linear = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, sequence, encoder_state):\n",
    "        embedding = self.word_embeddings(sequence)\n",
    "        # Many to Manyなので、第１戻り値を使う。\n",
    "        # 第２戻り値は推論時に次の文字を生成するときに使います。\n",
    "        output, state = self.lstm(embedding, encoder_state)\n",
    "        output = self.hidden2linear(output)\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モデル宣言、損失関数、最適化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU使えるように。\n",
    "encoder = Encoder(vocab_size, embedding_dim, hidden_dim).to(device)\n",
    "decoder = Decoder(vocab_size, embedding_dim, hidden_dim).to(device)\n",
    "\n",
    "# 損失関数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 最適化\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ...\n",
      "Epoch 1: 1867.84\n",
      "Epoch 2: 1357.92\n",
      "Epoch 3: 1171.56\n",
      "Epoch 4: 1043.47\n",
      "Epoch 5: 950.89\n",
      "Epoch 6: 869.63\n",
      "Epoch 7: 794.90\n",
      "Epoch 8: 713.12\n",
      "Epoch 9: 641.19\n",
      "Epoch 10: 568.59\n",
      "Epoch 11: 508.42\n",
      "Epoch 12: 456.14\n",
      "Epoch 13: 409.89\n",
      "Epoch 14: 371.99\n",
      "Epoch 15: 344.13\n",
      "Epoch 16: 319.73\n",
      "Epoch 17: 298.36\n",
      "Epoch 18: 280.74\n",
      "Epoch 19: 261.86\n",
      "Epoch 20: 243.94\n",
      "Epoch 21: 232.54\n",
      "Epoch 22: 214.79\n",
      "Epoch 23: 204.59\n",
      "Epoch 24: 193.75\n",
      "Epoch 25: 184.09\n",
      "Epoch 26: 172.26\n",
      "Epoch 27: 164.41\n",
      "Epoch 28: 161.77\n",
      "Epoch 29: 147.67\n",
      "Epoch 30: 146.47\n",
      "Epoch 31: 135.73\n",
      "Epoch 32: 133.70\n",
      "Epoch 33: 122.27\n",
      "Epoch 34: 117.42\n",
      "Epoch 35: 122.91\n",
      "Epoch 36: 113.32\n",
      "Epoch 37: 99.75\n",
      "Epoch 38: 105.60\n",
      "Epoch 39: 101.92\n",
      "Epoch 40: 93.16\n",
      "Epoch 41: 89.68\n",
      "Epoch 42: 88.13\n",
      "Epoch 43: 91.70\n",
      "Epoch 44: 92.61\n",
      "Epoch 45: 81.21\n",
      "Epoch 46: 67.62\n",
      "Epoch 47: 67.07\n",
      "Epoch 48: 77.73\n",
      "Epoch 49: 75.48\n",
      "Epoch 50: 60.91\n",
      "Epoch 51: 61.70\n",
      "Epoch 52: 67.64\n",
      "Epoch 53: 61.96\n",
      "Epoch 54: 63.43\n",
      "Epoch 55: 55.63\n",
      "Epoch 56: 46.90\n",
      "Epoch 57: 52.01\n",
      "Epoch 58: 63.12\n",
      "Epoch 59: 39.74\n",
      "Epoch 60: 44.75\n",
      "Epoch 61: 58.53\n",
      "Epoch 62: 41.87\n",
      "Epoch 63: 35.66\n",
      "Epoch 64: 47.01\n",
      "Epoch 65: 46.90\n",
      "Epoch 66: 42.91\n",
      "Epoch 67: 36.19\n",
      "Epoch 68: 27.86\n",
      "Epoch 69: 38.56\n",
      "Epoch 70: 35.62\n",
      "Epoch 71: 35.64\n",
      "Epoch 72: 27.40\n",
      "Epoch 73: 40.55\n",
      "Epoch 74: 32.89\n",
      "Epoch 75: 18.92\n",
      "Epoch 76: 18.18\n",
      "Epoch 77: 30.52\n",
      "Epoch 78: 60.54\n",
      "Epoch 79: 27.37\n",
      "Epoch 80: 15.08\n",
      "Epoch 81: 9.81\n",
      "Epoch 82: 7.41\n",
      "Epoch 83: 6.27\n",
      "Epoch 84: 11.68\n",
      "Epoch 85: 125.69\n",
      "Epoch 86: 25.82\n",
      "Epoch 87: 11.37\n",
      "Epoch 88: 6.80\n",
      "Epoch 89: 5.29\n",
      "Epoch 90: 4.87\n",
      "Epoch 91: 4.43\n",
      "Epoch 92: 50.76\n",
      "Epoch 93: 85.93\n",
      "Epoch 94: 23.58\n",
      "Epoch 95: 11.48\n",
      "Epoch 96: 5.70\n",
      "Epoch 97: 4.23\n",
      "Epoch 98: 3.64\n",
      "Epoch 99: 3.23\n",
      "Epoch 100: 2.89\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "BATCH_NUM = 100\n",
    "EPOCH_NUM = 100\n",
    "\n",
    "all_losses = []\n",
    "print(\"training ...\")\n",
    "for epoch in range(1, EPOCH_NUM + 1):\n",
    "    epoch_loss = 0  # epoch毎のloss\n",
    "\n",
    "    # データをミニバッチに分ける\n",
    "    input_batch, output_batch = train2batch(train_x, train_y, batch_size=BATCH_NUM)\n",
    "\n",
    "    for i in range(len(input_batch)):\n",
    "\n",
    "        # 勾配の初期化\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        # データをテンソルに変換\n",
    "        input_tensor = torch.tensor(input_batch[i], device=device)\n",
    "        output_tensor = torch.tensor(output_batch[i], device=device)\n",
    "\n",
    "        # Encoderの順伝搬\n",
    "        encoder_state = encoder(input_tensor)\n",
    "\n",
    "        # Decoderで使うデータはoutput_tensorを１つずらしたものを使う\n",
    "        # Decoderのインプットとするデータ\n",
    "        source = output_tensor[:, :-1]\n",
    "\n",
    "        # Decoderの教師データ\n",
    "        # 生成開始を表す\"_\"を削っている\n",
    "        target = output_tensor[:, 1:]\n",
    "\n",
    "        loss = 0\n",
    "        # 学習時はDecoderはこのように１回呼び出すだけでグルっと系列をループしているからこれでOK\n",
    "        # sourceが４文字なので、以下でLSTMが4回再帰的な処理してる\n",
    "        decoder_output, _ = decoder(source, encoder_state)\n",
    "        # decoder_output.size() = (100,4,13)\n",
    "        # 「13」は生成すべき対象の文字が13文字あるから。decoder_outputの3要素目は\n",
    "        # [-14.6240,  -3.7612, -11.0775,  ...,  -5.7391, -15.2419,  -8.6547]\n",
    "        # こんな感じの値が入っており、これの最大値に対応するインデックスを予測文字とみなす\n",
    "\n",
    "        for j in range(decoder_output.size()[1]):\n",
    "            # バッチ毎にまとめてloss計算\n",
    "            # 生成する文字は4文字なので、4回ループ\n",
    "            loss += criterion(decoder_output[:, j, :], target[:, j])\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # 誤差逆伝播\n",
    "        loss.backward()\n",
    "\n",
    "        # パラメータ更新\n",
    "        # Encoder、Decoder両方学習\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "    # 損失を表示\n",
    "    print(\"Epoch %d: %.2f\" % (epoch, epoch_loss))\n",
    "    all_losses.append(epoch_loss)\n",
    "    if epoch_loss < 1:\n",
    "        break\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 損失可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f082cf6a100>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "torch.Size([100, 5])\n"
     ]
    }
   ],
   "source": [
    "# Decoderのアウトプットのテンソルから要素が最大のインデックスを返す。つまり生成文字を意味する\n",
    "def get_max_index(decoder_output):\n",
    "    results = []\n",
    "    for h in decoder_output:\n",
    "        results.append(torch.argmax(h))\n",
    "    return torch.tensor(results, device=device).view(BATCH_NUM, 1)\n",
    "\n",
    "\n",
    "# 評価用データ\n",
    "test_input_batch, test_output_batch = train2batch(test_x, test_y)\n",
    "input_tensor = torch.tensor(test_input_batch, device=device)\n",
    "\n",
    "predicts = []\n",
    "for i in range(len(test_input_batch)):\n",
    "    with torch.no_grad():  # 勾配計算させない\n",
    "        encoder_state = encoder(input_tensor[i])\n",
    "\n",
    "    # Decoderにはまず文字列生成開始を表す\"_\"をインプットにするので、\"_\"のtensorをバッチサイズ分作成\n",
    "    start_char_batch = [[char2id[\"_\"]] for _ in range(BATCH_NUM)]\n",
    "    decoder_input_tensor = torch.tensor(start_char_batch, device=device)\n",
    "\n",
    "    # 変数名変換\n",
    "    decoder_hidden = encoder_state\n",
    "\n",
    "    # バッチ毎の結果を結合するための入れ物を定義\n",
    "    batch_tmp = torch.zeros(100, 1, dtype=torch.long, device=device)\n",
    "    # print(batch_tmp.size())\n",
    "    # (100,1)\n",
    "\n",
    "    for _ in range(5):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input_tensor, decoder_hidden)\n",
    "        # 予測文字を取得しつつ、そのまま次のdecoderのインプットとなる\n",
    "        decoder_input_tensor = get_max_index(decoder_output.squeeze())\n",
    "        # バッチ毎の結果を予測順に結合\n",
    "        batch_tmp = torch.cat([batch_tmp, decoder_input_tensor], dim=1)\n",
    "\n",
    "    # 最初のbatch_tmpの0要素が先頭に残ってしまっているのでスライスして削除\n",
    "    predicts.append(batch_tmp[:, 1:])\n",
    "\n",
    "# バッチ毎の予測結果がまとまって格納されてます。\n",
    "print(len(predicts))\n",
    "print(predicts[0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上でまとめたpredictsをDataFrameにまとめるための処理を以下で実行\n",
    "- ついでにaccuracyも計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8605333333333334\n",
      "      input answer predict judge\n",
      "1    284-31    253     263     X\n",
      "3    266-86    180     170     X\n",
      "15   94-380   -286    -206     X\n",
      "19  250-273    -23     -13     X\n",
      "25  883-110    773     783     X\n",
      "30  708-685     23       8     X\n",
      "40    602-9    593     603     X\n",
      "41   66-701   -635    -645     X\n",
      "55   99-342   -243    -233     X\n",
      "56   55-836   -781    -771     X\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "id2char = {str(i): str(i) for i in range(10)}\n",
    "id2char.update({\"10\": \"\", \"11\": \"-\", \"12\": \"\"})\n",
    "row = []\n",
    "for i in range(len(test_input_batch)):\n",
    "    batch_input = test_input_batch[i]\n",
    "    batch_output = test_output_batch[i]\n",
    "    batch_predict = predicts[i]\n",
    "    for inp, output, predict in zip(batch_input, batch_output, batch_predict):\n",
    "        x = [id2char[str(idx)] for idx in inp]\n",
    "        y = [id2char[str(idx)] for idx in output]\n",
    "        p = [id2char[str(idx.item())] for idx in predict]\n",
    "\n",
    "        x_str = \"\".join(x)\n",
    "        y_str = \"\".join(y)\n",
    "        p_str = \"\".join(p)\n",
    "\n",
    "        judge = \"O\" if y_str == p_str else \"X\"\n",
    "        row.append([x_str, y_str, p_str, judge])\n",
    "predict_df = pd.DataFrame(row, columns=[\"input\", \"answer\", \"predict\", \"judge\"])\n",
    "\n",
    "# 正解率を表示\n",
    "print(len(predict_df.query('judge == \"O\"')) / len(predict_df))\n",
    "\n",
    "# 間違えたデータを一部見てみる\n",
    "print(predict_df.query('judge == \"X\"').head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
